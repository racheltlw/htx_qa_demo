{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d37d10",
   "metadata": {},
   "source": [
    "## Demo for Question and Answering System (Multi) \n",
    "\n",
    "This demo will walk you through how to train a Question and Answering pipeline using Haystack for Multiple Document QA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d34c7",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adeb31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure you have a GPU running\n",
    "!nvidia-smi #for windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc693de",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13654e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel Tan\\Documents\\France Trip\\htx_qa_demo\\testvenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.nodes import PreProcessor, DensePassageRetriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.nodes import FARMReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa936a",
   "metadata": {},
   "source": [
    "#### 2. Create a document store\n",
    "\n",
    "Think of this as a database where your documents will be stored, to be used by the QA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59855ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore() \n",
    "#you can also use a faiss document store which is optimised vector storage for DPR, for simplicity sake we will use InMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02caa5",
   "metadata": {},
   "source": [
    "#### 3. Load and format your data \n",
    "The data a CSV file containing covid 19 related information. We will see how a haystack retriever can filter for the most relevant articles to a question, before using a QA model to extract the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747df368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data as a pandas dataframe\n",
    "df = pd.read_csv('multi_demo_covid.csv') #load into the correct format for the haystack pipeline\n",
    "#load reader and retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cf76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat data so that haystack framework can use it\n",
    "def get_docs(input_df):\n",
    "    docs = []\n",
    "    for i in range(len(input_df)): \n",
    "        doc = {\n",
    "            'content': input_df['text'][i], \n",
    "            'meta': {'link': input_df['link'][i], \n",
    "                    'source': input_df['source'][i]}\n",
    "        }\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0875094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some articles are quite long so we need to split them into smaller chunks\n",
    "preprocessor = PreProcessor(split_by = 'word', \n",
    "                            split_length = 300, #each chunk is 300 words long\n",
    "                            split_overlap = 30, #each chunk overlaps with the previous chunk by 30 words\n",
    "                            split_respect_sentence_boundary= True) #will split according to complete sentences \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873f9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|█████████████████████████████████████████████████████████████| 213/213 [00:00<00:00, 4797.82docs/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_docs(df)\n",
    "preprocessed_data = preprocessor.process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056d48b",
   "metadata": {},
   "source": [
    "Write our data into the document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ec4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77c70b",
   "metadata": {},
   "source": [
    "#### 4. Load DPR and QA Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3837a",
   "metadata": {},
   "source": [
    "Load the DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c24df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Updating Embedding:   0%|                                                                   | 0/218 [00:00<?, ? docs/s]\n",
      "Create embeddings:   0%|                                                                    | 0/224 [00:00<?, ? Docs/s]\u001b[A\n",
      "Create embeddings:   7%|████▏                                                      | 16/224 [00:01<00:24,  8.36 Docs/s]\u001b[A\n",
      "Create embeddings:  14%|████████▍                                                  | 32/224 [00:02<00:11, 16.33 Docs/s]\u001b[A\n",
      "Create embeddings:  21%|████████████▋                                              | 48/224 [00:02<00:07, 23.50 Docs/s]\u001b[A\n",
      "Create embeddings:  29%|████████████████▊                                          | 64/224 [00:02<00:05, 29.47 Docs/s]\u001b[A\n",
      "Create embeddings:  36%|█████████████████████                                      | 80/224 [00:03<00:04, 34.38 Docs/s]\u001b[A\n",
      "Create embeddings:  43%|█████████████████████████▎                                 | 96/224 [00:03<00:03, 38.24 Docs/s]\u001b[A\n",
      "Create embeddings:  50%|█████████████████████████████                             | 112/224 [00:03<00:02, 41.14 Docs/s]\u001b[A\n",
      "Create embeddings:  57%|█████████████████████████████████▏                        | 128/224 [00:04<00:02, 43.23 Docs/s]\u001b[A\n",
      "Create embeddings:  64%|█████████████████████████████████████▎                    | 144/224 [00:04<00:01, 44.82 Docs/s]\u001b[A\n",
      "Create embeddings:  71%|█████████████████████████████████████████▍                | 160/224 [00:04<00:01, 45.81 Docs/s]\u001b[A\n",
      "Create embeddings:  79%|█████████████████████████████████████████████▌            | 176/224 [00:05<00:01, 46.60 Docs/s]\u001b[A\n",
      "Create embeddings:  86%|█████████████████████████████████████████████████▋        | 192/224 [00:05<00:00, 47.29 Docs/s]\u001b[A\n",
      "Create embeddings:  93%|█████████████████████████████████████████████████████▊    | 208/224 [00:05<00:00, 47.60 Docs/s]\u001b[A\n",
      "Create embeddings: 100%|██████████████████████████████████████████████████████████| 224/224 [00:06<00:00, 53.81 Docs/s]\u001b[A\n",
      "Documents Processed: 10000 docs [00:06, 1602.93 docs/s]                                                                \u001b[A\n"
     ]
    }
   ],
   "source": [
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    max_seq_len_query=128, \n",
    "    max_seq_len_passage=512,\n",
    "    batch_size=16,\n",
    "    use_gpu=True, #if you do not have a gpu you can turn this off, it will just take longer\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b2f3c",
   "metadata": {},
   "source": [
    "Load the Reader (this is the QA model from Huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0521e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc6c9d",
   "metadata": {},
   "source": [
    "Create a pipeline using both the retriever and reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b7fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c9cea",
   "metadata": {},
   "source": [
    "#### 5. Trying out our pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2e6cc",
   "metadata": {},
   "source": [
    "Here is a simple function to allow us to display our results nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preds_df(results):\n",
    "    answers = results[\"answers\"]\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    keys_to_keep = set([\"answer\", \"context\", \"score\", \"probability\"])\n",
    "\n",
    "    # filter the results\n",
    "    filtered_answers = []\n",
    "    for ans in answers:\n",
    "        filtered_answers.append({'answer': ans.answer, 'context': ans.context, 'score': ans.score, \n",
    "                               'link': ans.meta['link'], 'source': ans.meta['source']})\n",
    "\n",
    "    df_res = pd.DataFrame({\"answer\":[], \"context\":[], \"score\":[], \"link\":[], \"source\":[]})\n",
    "\n",
    "    for i in filtered_answers:\n",
    "        df_res.loc[len(df_res)] = i\n",
    "\n",
    "    df_res.sort_values(by=['score'], inplace = True, ascending=False)\n",
    "    df_res = df_res.reset_index(drop = True)\n",
    "    df_res['score'] = df_res['score'].round(2)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66effcfa",
   "metadata": {},
   "source": [
    "Run the pipeline on a question \n",
    "- The retriever filters out the top 20 most relevant articles\n",
    "- Then the QA finds the top 5 most probable answers from those articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9cb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.63 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.39 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.66 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.48 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.91 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.64 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.44 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 46.70 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.59 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 51.89 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.37 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.72 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 41.60 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.93 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.46 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.66 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.68 Batches/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wuhan China</td>\n",
       "      <td>t is causing the 2019 novel coronavirus outbreak, first identified in Wuhan ...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>\\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html</td>\n",
       "      <td>Center for Disease Control and Prevention (CDC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>The novel coronavirus detected in China is genetically closely related to th...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>https://www.ecdc.europa.eu/en/novel-coronavirus-china/questions-answers</td>\n",
       "      <td>European Centre for Disease Prevention and Control (ECDC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animals</td>\n",
       "      <td>Coronaviruses are a large family of viruses that are common in animals. Occa...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>https://www.who.int/news-room/q-a-detail/q-a-coronaviruses</td>\n",
       "      <td>World Health Organization (WHO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humans</td>\n",
       "      <td>ily of viruses. There are some coronaviruses that commonly circulate in huma...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wuhan City</td>\n",
       "      <td>This virus was first detected in Wuhan City, Hubei Province, China. The firs...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>\\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html</td>\n",
       "      <td>Center for Disease Control and Prevention (CDC)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer  \\\n",
       "0  Wuhan China   \n",
       "1        China   \n",
       "2      animals   \n",
       "3       humans   \n",
       "4   Wuhan City   \n",
       "\n",
       "                                                                           context  \\\n",
       "0  t is causing the 2019 novel coronavirus outbreak, first identified in Wuhan ...   \n",
       "1  The novel coronavirus detected in China is genetically closely related to th...   \n",
       "2  Coronaviruses are a large family of viruses that are common in animals. Occa...   \n",
       "3  ily of viruses. There are some coronaviruses that commonly circulate in huma...   \n",
       "4  This virus was first detected in Wuhan City, Hubei Province, China. The firs...   \n",
       "\n",
       "   score  \\\n",
       "0   0.97   \n",
       "1   0.85   \n",
       "2   0.77   \n",
       "3   0.73   \n",
       "4   0.70   \n",
       "\n",
       "                                                                          link  \\\n",
       "0                         \\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html   \n",
       "1      https://www.ecdc.europa.eu/en/novel-coronavirus-china/questions-answers   \n",
       "2                   https://www.who.int/news-room/q-a-detail/q-a-coronaviruses   \n",
       "3  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "4                         \\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html   \n",
       "\n",
       "                                                      source  \n",
       "0            Center for Disease Control and Prevention (CDC)  \n",
       "1  European Centre for Disease Prevention and Control (ECDC)  \n",
       "2                            World Health Organization (WHO)  \n",
       "3                     California Department of Public Health  \n",
       "4            Center for Disease Control and Prevention (CDC)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn = 'Where did the coronavirus first appear? '\n",
    "prediction = pipeline.run(query=qn, params={'Retriever': {'top_k': 20}, 'Reader': {'top_k':5}})\n",
    "prediction_df = print_preds_df(prediction)\n",
    "prediction_df #shows the top 5 answers by score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('testvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ae9c111b34fa2e30ace2c16e524dd84b3f0c1b33f3eeae7e190ba6ff380807a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
