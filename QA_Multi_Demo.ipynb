{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d37d10",
   "metadata": {},
   "source": [
    "## Demo for Question and Answering System (Multi) \n",
    "\n",
    "This demo will walk you through how to train a Question and Answering pipeline using Haystack for Multiple Document QA  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d34c7",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9adeb31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 10 15:39:46 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 512.36       Driver Version: 512.36       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   53C    P8     9W /  N/A |   3282MiB / 16384MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      6140    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     12500      C   ...ython\\Python39\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     13432    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16080    C+G   ...urrent\\LogiOptionsMgr.exe    N/A      |\n",
      "|    0   N/A  N/A     16108    C+G   ...e\\Current\\LogiOverlay.exe    N/A      |\n",
      "|    0   N/A  N/A     16752    C+G   ...ontend\\Docker Desktop.exe    N/A      |\n",
      "|    0   N/A  N/A     20172    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     20816    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     22288    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     24732    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     26308    C+G   ...\\atom\\app-1.58.0\\atom.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have a GPU running\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc693de",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13654e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachel Tan\\Documents\\France Trip\\htx_qa_demo\\testvenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pprint\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.nodes import PreProcessor, DensePassageRetriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.nodes import FARMReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa936a",
   "metadata": {},
   "source": [
    "#### 2. Create a document store\n",
    "\n",
    "Think of this as a database where your documents will be stored, to be used by the QA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59855ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore() \n",
    "#you cam also use a faiss document store which is optimised vector storage for DPR, for simplicity sake we will use InMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02caa5",
   "metadata": {},
   "source": [
    "#### 3. Load and format your data \n",
    "The data a CSV file containing covid 19 related information. We will see how a haystack retriever can filter for the most relevant articles to a question, before using a QA model to extract the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747df368",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data as a pandas dataframe\n",
    "df = pd.read_csv('multi_demo_covid.csv') #load into the correct format for the haystack pipeline\n",
    "#load reader and retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cf76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat data so that haystack framework can use it\n",
    "def get_docs(input_df):\n",
    "    docs = []\n",
    "    for i in range(len(input_df)): \n",
    "        doc = {\n",
    "            'content': input_df['text'][i], \n",
    "            'meta': {'link': input_df['link'][i], \n",
    "                    'source': input_df['source'][i]}\n",
    "        }\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0875094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some articles are quite long so we need to split them into smaller chunks\n",
    "preprocessor = PreProcessor(split_by = 'word', \n",
    "                            split_length = 300, #each chunk is 300 words long\n",
    "                            split_overlap = 30, #each chunk overlaps with the previous chunk by 30 words\n",
    "                            split_respect_sentence_boundary= True) #will split according to complete sentences \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873f9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|█████████████████████████████████████████████████████████████| 213/213 [00:00<00:00, 4797.82docs/s]\n"
     ]
    }
   ],
   "source": [
    "data = get_docs(df)\n",
    "preprocessed_data = preprocessor.process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056d48b",
   "metadata": {},
   "source": [
    "Write our data into the document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ec4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.write_documents(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77c70b",
   "metadata": {},
   "source": [
    "#### 4. Load DPR and QA Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3837a",
   "metadata": {},
   "source": [
    "Load the DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c24df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Updating Embedding:   0%|                                                                   | 0/218 [00:00<?, ? docs/s]\n",
      "Create embeddings:   0%|                                                                    | 0/224 [00:00<?, ? Docs/s]\u001b[A\n",
      "Create embeddings:   7%|████▏                                                      | 16/224 [00:01<00:24,  8.36 Docs/s]\u001b[A\n",
      "Create embeddings:  14%|████████▍                                                  | 32/224 [00:02<00:11, 16.33 Docs/s]\u001b[A\n",
      "Create embeddings:  21%|████████████▋                                              | 48/224 [00:02<00:07, 23.50 Docs/s]\u001b[A\n",
      "Create embeddings:  29%|████████████████▊                                          | 64/224 [00:02<00:05, 29.47 Docs/s]\u001b[A\n",
      "Create embeddings:  36%|█████████████████████                                      | 80/224 [00:03<00:04, 34.38 Docs/s]\u001b[A\n",
      "Create embeddings:  43%|█████████████████████████▎                                 | 96/224 [00:03<00:03, 38.24 Docs/s]\u001b[A\n",
      "Create embeddings:  50%|█████████████████████████████                             | 112/224 [00:03<00:02, 41.14 Docs/s]\u001b[A\n",
      "Create embeddings:  57%|█████████████████████████████████▏                        | 128/224 [00:04<00:02, 43.23 Docs/s]\u001b[A\n",
      "Create embeddings:  64%|█████████████████████████████████████▎                    | 144/224 [00:04<00:01, 44.82 Docs/s]\u001b[A\n",
      "Create embeddings:  71%|█████████████████████████████████████████▍                | 160/224 [00:04<00:01, 45.81 Docs/s]\u001b[A\n",
      "Create embeddings:  79%|█████████████████████████████████████████████▌            | 176/224 [00:05<00:01, 46.60 Docs/s]\u001b[A\n",
      "Create embeddings:  86%|█████████████████████████████████████████████████▋        | 192/224 [00:05<00:00, 47.29 Docs/s]\u001b[A\n",
      "Create embeddings:  93%|█████████████████████████████████████████████████████▊    | 208/224 [00:05<00:00, 47.60 Docs/s]\u001b[A\n",
      "Create embeddings: 100%|██████████████████████████████████████████████████████████| 224/224 [00:06<00:00, 53.81 Docs/s]\u001b[A\n",
      "Documents Processed: 10000 docs [00:06, 1602.93 docs/s]                                                                \u001b[A\n"
     ]
    }
   ],
   "source": [
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    max_seq_len_query=128, \n",
    "    max_seq_len_passage=512,\n",
    "    batch_size=16,\n",
    "    use_gpu=True, #if you do not have a gpu you can turn this off, it will just take longer\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b2f3c",
   "metadata": {},
   "source": [
    "Load the Reader (this is the QA model from Huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0521e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bc6c9d",
   "metadata": {},
   "source": [
    "Create a pipeline using both the retriever and reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b7fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ExtractiveQAPipeline(reader, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c9cea",
   "metadata": {},
   "source": [
    "#### 5. Trying out our pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2e6cc",
   "metadata": {},
   "source": [
    "Here is a simple function to allow us to display our results nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda3712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preds_df(results):\n",
    "    answers = results[\"answers\"]\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    keys_to_keep = set([\"answer\", \"context\", \"score\", \"probability\"])\n",
    "\n",
    "    # filter the results\n",
    "    filtered_answers = []\n",
    "    for ans in answers:\n",
    "        filtered_answers.append({'answer': ans.answer, 'context': ans.context, 'score': ans.score, \n",
    "                               'link': ans.meta['link'], 'source': ans.meta['source']})\n",
    "\n",
    "    df_res = pd.DataFrame({\"answer\":[], \"context\":[], \"score\":[], \"link\":[], \"source\":[]})\n",
    "\n",
    "    for i in filtered_answers:\n",
    "        df_res.loc[len(df_res)] = i\n",
    "\n",
    "    df_res.sort_values(by=['score'], inplace = True, ascending=False)\n",
    "    df_res = df_res.reset_index(drop = True)\n",
    "    df_res['score'] = df_res['score'].round(2)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66effcfa",
   "metadata": {},
   "source": [
    "Run the pipeline on a question \n",
    "- The retriever filters out the top 20 most relevant articles\n",
    "- Then the QA finds the top 5 most probable answers from those articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9cb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.36 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.63 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.39 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.66 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.48 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 24.91 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 25.64 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.44 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 46.70 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.59 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 51.89 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.37 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.72 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 41.60 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.93 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.46 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.66 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.68 Batches/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wuhan China</td>\n",
       "      <td>t is causing the 2019 novel coronavirus outbreak, first identified in Wuhan ...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>\\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html</td>\n",
       "      <td>Center for Disease Control and Prevention (CDC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>China</td>\n",
       "      <td>The novel coronavirus detected in China is genetically closely related to th...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>https://www.ecdc.europa.eu/en/novel-coronavirus-china/questions-answers</td>\n",
       "      <td>European Centre for Disease Prevention and Control (ECDC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animals</td>\n",
       "      <td>Coronaviruses are a large family of viruses that are common in animals. Occa...</td>\n",
       "      <td>0.77</td>\n",
       "      <td>https://www.who.int/news-room/q-a-detail/q-a-coronaviruses</td>\n",
       "      <td>World Health Organization (WHO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humans</td>\n",
       "      <td>ily of viruses. There are some coronaviruses that commonly circulate in huma...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wuhan City</td>\n",
       "      <td>This virus was first detected in Wuhan City, Hubei Province, China. The firs...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>\\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html</td>\n",
       "      <td>Center for Disease Control and Prevention (CDC)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer  \\\n",
       "0  Wuhan China   \n",
       "1        China   \n",
       "2      animals   \n",
       "3       humans   \n",
       "4   Wuhan City   \n",
       "\n",
       "                                                                           context  \\\n",
       "0  t is causing the 2019 novel coronavirus outbreak, first identified in Wuhan ...   \n",
       "1  The novel coronavirus detected in China is genetically closely related to th...   \n",
       "2  Coronaviruses are a large family of viruses that are common in animals. Occa...   \n",
       "3  ily of viruses. There are some coronaviruses that commonly circulate in huma...   \n",
       "4  This virus was first detected in Wuhan City, Hubei Province, China. The firs...   \n",
       "\n",
       "   score  \\\n",
       "0   0.97   \n",
       "1   0.85   \n",
       "2   0.77   \n",
       "3   0.73   \n",
       "4   0.70   \n",
       "\n",
       "                                                                          link  \\\n",
       "0                         \\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html   \n",
       "1      https://www.ecdc.europa.eu/en/novel-coronavirus-china/questions-answers   \n",
       "2                   https://www.who.int/news-room/q-a-detail/q-a-coronaviruses   \n",
       "3  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "4                         \\nhttps://www.cdc.gov/coronavirus/2019-ncov/faq.html   \n",
       "\n",
       "                                                      source  \n",
       "0            Center for Disease Control and Prevention (CDC)  \n",
       "1  European Centre for Disease Prevention and Control (ECDC)  \n",
       "2                            World Health Organization (WHO)  \n",
       "3                     California Department of Public Health  \n",
       "4            Center for Disease Control and Prevention (CDC)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn = 'Where did the coronavirus first appear? '\n",
    "prediction = pipeline.run(query=qn, params={'Retriever': {'top_k': 20}, 'Reader': {'top_k':5}})\n",
    "prediction_df = print_preds_df(prediction)\n",
    "prediction_df #shows the top 5 answers by score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc2d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.30 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.54 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 33.33 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.62 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 47.62 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.83 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 61.33 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.00 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.56 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 43.48 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.67 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.39 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.44 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.70 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.67 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 65.94 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.50 Batches/s]\n",
      "Inferencing Samples: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.05 Batches/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>safe return of 962 Californians from the Grand Princess cruise ship</td>\n",
       "      <td>with the federal government to aid in the safe return of 962 Californians fr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unwashed hands</td>\n",
       "      <td>act with sick people. Avoid touching your eyes, nose, or mouth with unwashed...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cdc.gov/coronavirus/2019-ncov/travelers/faqs.html</td>\n",
       "      <td>Center for Disease Control and Prevention (CDC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>) is encouraging individuals who are unable to work due to exposure to COVID...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our Medical and Health Coordination Center has been activated and is coordin...</td>\n",
       "      <td>our Medical and Health Coordination Center has been activated and is coordin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slow the spread of the virus</td>\n",
       "      <td>state directed mass gatherings be postponed or cancelled to slow the spread...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#</td>\n",
       "      <td>California Department of Public Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            answer  \\\n",
       "0              safe return of 962 Californians from the Grand Princess cruise ship   \n",
       "1                                                                   unwashed hands   \n",
       "2                                                                         COVID-19   \n",
       "3  our Medical and Health Coordination Center has been activated and is coordin...   \n",
       "4                                                     slow the spread of the virus   \n",
       "\n",
       "                                                                           context  \\\n",
       "0  with the federal government to aid in the safe return of 962 Californians fr...   \n",
       "1  act with sick people. Avoid touching your eyes, nose, or mouth with unwashed...   \n",
       "2  ) is encouraging individuals who are unable to work due to exposure to COVID...   \n",
       "3  our Medical and Health Coordination Center has been activated and is coordin...   \n",
       "4   state directed mass gatherings be postponed or cancelled to slow the spread...   \n",
       "\n",
       "   score  \\\n",
       "0    0.0   \n",
       "1    0.0   \n",
       "2    0.0   \n",
       "3    0.0   \n",
       "4    0.0   \n",
       "\n",
       "                                                                          link  \\\n",
       "0  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "1                https://www.cdc.gov/coronavirus/2019-ncov/travelers/faqs.html   \n",
       "2  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "3  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "4  https://www.cdph.ca.gov/Programs/CID/DCDC/Pages/Immunization/nCoV2019.aspx#   \n",
       "\n",
       "                                            source  \n",
       "0           California Department of Public Health  \n",
       "1  Center for Disease Control and Prevention (CDC)  \n",
       "2           California Department of Public Health  \n",
       "3           California Department of Public Health  \n",
       "4           California Department of Public Health  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qn = \"What happened on Halloween at Marina Bay Sands?\"\n",
    "prediction = pipeline.run(query=qn, params={'Retriever': {'top_k': 20}, 'Reader': {'top_k':5}})\n",
    "prediction_df = print_preds_df(prediction)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa1eed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "testvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
